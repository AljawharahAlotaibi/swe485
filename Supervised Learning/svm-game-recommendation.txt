{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: SVM Model for Game Recommendation System\n",
    "# SWE485: Selected Topics in Software Engineering\n",
    "\n",
    "## Team Members:\n",
    "- [Your Name]\n",
    "- [Team Member Names]\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we implement a Support Vector Machine (SVM) model for our game recommendation system. While our teammate has implemented a K-Nearest Neighbors (KNN) approach, we'll use SVM to provide an alternative recommendation method that can be compared with KNN.\n",
    "\n",
    "Our recommendation system works as follows:\n",
    "1. The user provides a game image/poster (URL)\n",
    "2. The system identifies the game associated with this image\n",
    "3. Using SVM, the system finds similar games based on features like genres, categories, descriptions, etc.\n",
    "4. The system recommends 3 similar games to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/AljawharahAlotaibi/swe485/main/Dataset/updated_cleaned_games.xls\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique genres and categories\n",
    "# Convert the string representations to lists first\n",
    "df['genres_list'] = df['genres_y'].astype(str).apply(lambda x: ast.literal_eval(x) if x != 'nan' else [])\n",
    "df['categories_list'] = df['categories_y'].astype(str).apply(lambda x: ast.literal_eval(x) if x != 'nan' else [])\n",
    "\n",
    "# Get all unique genres and categories\n",
    "all_genres = set()\n",
    "all_categories = set()\n",
    "\n",
    "for genres in df['genres_list']:\n",
    "    all_genres.update(genres)\n",
    "    \n",
    "for categories in df['categories_list']:\n",
    "    all_categories.update(categories)\n",
    "\n",
    "print(f\"Number of unique genres: {len(all_genres)}\")\n",
    "print(f\"Number of unique categories: {len(all_categories)}\")\n",
    "\n",
    "# Display the most common genres and categories\n",
    "from collections import Counter\n",
    "\n",
    "genre_counts = Counter()\n",
    "for genres in df['genres_list']:\n",
    "    genre_counts.update(genres)\n",
    "    \n",
    "category_counts = Counter()\n",
    "for categories in df['categories_list']:\n",
    "    category_counts.update(categories)\n",
    "\n",
    "print(\"\\nTop 10 most common genres:\")\n",
    "for genre, count in genre_counts.most_common(10):\n",
    "    print(f\"{genre}: {count}\")\n",
    "    \n",
    "print(\"\\nTop 10 most common categories:\")\n",
    "for category, count in category_counts.most_common(10):\n",
    "    print(f\"{category}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "We need to preprocess our data to prepare it for the SVM model. This includes:\n",
    "1. Converting string representations of lists to actual lists\n",
    "2. Creating binary encodings for genres and categories\n",
    "3. Processing text descriptions using TF-IDF\n",
    "4. Combining all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary feature vectors for genres and categories\n",
    "mlb_genres = MultiLabelBinarizer()\n",
    "genre_encoded = mlb_genres.fit_transform(df['genres_list'])\n",
    "genre_df = pd.DataFrame(genre_encoded, columns=mlb_genres.classes_)\n",
    "\n",
    "mlb_categories = MultiLabelBinarizer()\n",
    "category_encoded = mlb_categories.fit_transform(df['categories_list'])\n",
    "category_df = pd.DataFrame(category_encoded, columns=mlb_categories.classes_)\n",
    "\n",
    "# Text feature extraction using TF-IDF for detailed descriptions\n",
    "tfidf = TfidfVectorizer(max_features=300, stop_words='english')\n",
    "description_features = tfidf.fit_transform(df['detailed_description'].fillna(''))\n",
    "description_df = pd.DataFrame(description_features.toarray())\n",
    "\n",
    "# Add index from original DataFrame to all feature DataFrames\n",
    "genre_df.index = df.index\n",
    "category_df.index = df.index\n",
    "description_df.index = df.index\n",
    "\n",
    "# Combine all features\n",
    "# Basic numerical features\n",
    "numeric_cols = ['required_age', 'price']\n",
    "numeric_df = df[numeric_cols].copy()\n",
    "\n",
    "# Platform features (binary)\n",
    "platform_cols = ['windows', 'mac', 'linux']\n",
    "platform_df = df[platform_cols].astype(int).copy()\n",
    "\n",
    "# Combine all features\n",
    "all_features_df = pd.concat([numeric_df, platform_df, genre_df, category_df], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "if len(numeric_cols) > 0:\n",
    "    all_features_df[numeric_cols] = scaler.fit_transform(all_features_df[numeric_cols])\n",
    "\n",
    "print(f\"Shape of combined features: {all_features_df.shape}\")\n",
    "all_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM Model Implementation\n",
    "\n",
    "Now we'll implement the SVM model. For this approach, we'll:\n",
    "1. Use genres as our target variable (treating this as a classification problem)\n",
    "2. Train the SVM to recognize patterns between game features and genres\n",
    "3. Use the SVM's decision function to find similar games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable (using the primary genre of each game)\n",
    "df['primary_genre'] = df['genres_list'].apply(lambda x: x[0] if len(x) > 0 else 'Unknown')\n",
    "df['primary_genre'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = all_features_df\n",
    "y = df['primary_genre']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a basic SVM model first\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"SVM model accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for top genres\n",
    "top_genres = df['primary_genre'].value_counts().head(10).index.tolist()\n",
    "mask = (y_test.isin(top_genres)) & (pd.Series(y_pred).isin(top_genres))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(y_test[mask], np.array(y_pred)[mask], labels=top_genres)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=top_genres, yticklabels=top_genres)\n",
    "plt.title('SVM: Confusion Matrix (Top 10 Genres)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(probability=True, random_state=42),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter tuning for SVM...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate best model\n",
    "best_y_pred = best_svm_model.predict(X_test)\n",
    "best_accuracy = accuracy_score(y_test, best_y_pred)\n",
    "print(f\"\\nBest SVM model accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Print classification report for best model\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "print(classification_report(y_test, best_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the Game Recommendation System using SVM\n",
    "\n",
    "Now that we have a trained SVM model, we'll use it to build our recommendation system. We'll define functions to:\n",
    "1. Identify a game from an image URL\n",
    "2. Find similar games using SVM-based similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract game info from image URL\n",
    "def get_game_from_image(image_url, df):\n",
    "    \"\"\"Extract game information from the image URL\"\"\"\n",
    "    # Try to extract app ID from the URL\n",
    "    app_id_pattern = r'steam/apps/(\\d+)/header'\n",
    "    match = re.search(app_id_pattern, image_url)\n",
    "    \n",
    "    if match:\n",
    "        app_id = match.group(1)\n",
    "        # Find the game with this app ID\n",
    "        game = df[df['AppID'] == int(app_id)]\n",
    "        \n",
    "        if not game.empty:\n",
    "            return game.iloc[0]\n",
    "        else:\n",
    "            print(f\"No game found with AppID: {app_id}\")\n",
    "            return None\n",
    "    else:\n",
    "        # Try a more flexible approach - look for the image URL directly\n",
    "        game = df[df['header_image'] == image_url]\n",
    "        \n",
    "        if not game.empty:\n",
    "            return game.iloc[0]\n",
    "        else:\n",
    "            print(\"Could not identify game from the provided image URL\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find similar games using SVM\n",
    "def find_similar_games_svm(game_info, df, feature_df, svm_model, top_n=3):\n",
    "    \"\"\"Find similar games using SVM-based similarity\"\"\"\n",
    "    if game_info is None:\n",
    "        return None\n",
    "    \n",
    "    game_index = df[df['AppID'] == game_info['AppID']].index[0]\n",
    "    game_features = feature_df.loc[game_index].values.reshape(1, -1)\n",
    "    \n",
    "    # Method 1: Use SVM decision function scores directly\n",
    "    # This gives us the distance to the decision boundary for each class\n",
    "    # We can use this to find games that the model \"thinks\" are similar\n",
    "    decision_scores = svm_model.decision_function(feature_df)\n",
    "    \n",
    "    # Get the decision scores for our target game\n",
    "    game_decision_scores = svm_model.decision_function(game_features)[0]\n",
    "    \n",
    "    # Calculate similarity based on decision score patterns\n",
    "    similarities = []\n",
    "    for i, other_scores in enumerate(decision_scores):\n",
    "        if i == game_index:  # Skip the input game\n",
    "            similarities.append((i, -float('inf')))  # Negative infinity to ensure it's not recommended\n",
    "        else:\n",
    "            # Cosine similarity between decision score vectors\n",
    "            sim = cosine_similarity([game_decision_scores], [other_scores])[0][0]\n",
    "            similarities.append((i, sim))\n",
    "    \n",
    "    # Sort by similarity (descending)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top N similar games\n",
    "    top_indices = [idx for idx, _ in similarities[:top_n]]\n",
    "    similar_games = df.iloc[top_indices]\n",
    "    \n",
    "    return similar_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach: Use genre similarity directly\n",
    "def find_similar_games_genre(game_info, df, feature_df, top_n=3):\n",
    "    \"\"\"Find similar games based on genre similarity\"\"\"\n",
    "    if game_info is None:\n",
    "        return None\n",
    "    \n",
    "    game_index = df[df['AppID'] == game_info['AppID']].index[0]\n",
    "    \n",
    "    # Extract only genre and category features\n",
    "    genre_cat_features = feature_df.iloc[:, 5:]  # Skip numerical and platform features\n",
    "    \n",
    "    # Calculate cosine similarity between all games based on genres and categories\n",
    "    similarity_matrix = cosine_similarity(genre_cat_features)\n",
    "    \n",
    "    # Get similarity scores for the input game\n",
    "    game_similarities = similarity_matrix[game_index]\n",
    "    \n",
    "    # Create a list of (index, similarity) tuples\n",
    "    similarities = [(i, sim) for i, sim in enumerate(game_similarities)]\n",
    "    \n",
    "    # Set the similarity of the input game to -inf so it's not recommended\n",
    "    similarities[game_index] = (game_index, -float('inf'))\n",
    "    \n",
    "    # Sort by similarity (descending)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top N similar games\n",
    "    top_indices = [idx for idx, _ in similarities[:top_n]]\n",
    "    similar_games = df.iloc[top_indices]\n",
    "    \n",
    "    return similar_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete recommendation function that uses both approaches\n",
    "def recommend_games(image_url, df, feature_df, svm_model, method='genre', top_n=3):\n",
    "    \"\"\"Complete game recommendation pipeline\"\"\"\n",
    "    # Step 1: Identify the game from the image URL\n",
    "    game_info = get_game_from_image(image_url, df)\n",
    "    \n",
    "    if game_info is None:\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nIdentified Game: {game_info['name']}\")\n",
    "    print(f\"AppID: {game_info['AppID']}\")\n",
    "    print(f\"Genres: {game_info['genres_list']}\")\n",
    "    print(f\"Categories: {game_info['categories_list']}\")\n",
    "    \n",
    "    # Step 2: Find similar games based on the specified method\n",
    "    if method == 'svm':\n",
    "        similar_games = find_similar_games_svm(game_info, df, feature_df, svm_model, top_n)\n",
    "        method_name = \"SVM-based similarity\"\n",
    "    else:  # Default to genre method\n",
    "        similar_games = find_similar_games_genre(game_info, df, feature_df, top_n)\n",
    "        method_name = \"Genre/Category similarity\"\n",
    "    \n",
    "    if similar_games is None:\n",
    "        return None\n",
    "    \n",
    "    # Print recommendations\n",
    "    print(f\"\\n--- Recommended Games (using {method_name}) ---\")\n",
    "    for i, (_, game) in enumerate(similar_games.iterrows()):\n",
    "        print(f\"\\n{i+1}. {game['name']}\")\n",
    "        print(f\"   AppID: {game['AppID']}\")\n",
    "        print(f\"   Genres: {game['genres_list']}\")\n",
    "        print(f\"   Categories: {game['categories_list']}\")\n",
    "        print(f\"   Image URL: {game['header_image']}\")\n",
    "    \n",
    "    return similar_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing the Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample game image\n",
    "test_image_url = \"https://cdn.akamai.steamstatic.com/steam/apps/403970/header.jpg?t=1562768426\"  # The Dwarves\n",
    "\n",
    "# Test genre-based recommendations\n",
    "print(\"===== Testing Genre-Based Recommendations =====\")\n",
    "genre_recommendations = recommend_games(test_image_url, df, all_features_df, best_svm_model, method='genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SVM-based recommendations\n",
    "print(\"\\n\\n===== Testing SVM-Based Recommendations =====\")\n",
    "svm_recommendations = recommend_games(test_image_url, df, all_features_df, best_svm_model, method='svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another game\n",
    "test_image_url2 = \"https://cdn.akamai.steamstatic.com/steam/apps/2438430/header.jpg?t=1684930054\"\n",
    "\n",
    "# Test with another game\n",
    "print(\"\\n\\n===== Testing with Another Game =====\")\n",
    "another_recommendations = recommend_games(test_image_url2, df, all_features_df, best_svm_model, method='genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation of the Recommendation System\n",
    "\n",
    "We'll evaluate our recommendation system using standard metrics for recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate recommendations\n",
    "def precision_at_k(recommended_games, ground_truth_games, k=3):\n",
    "    \"\"\"Calculate precision@k for recommendations\"\"\"\n",
    "    recommended_set = set(recommended_games[:k])\n",
    "    ground_truth_set = set(ground_truth_games)\n",
    "    relevant_recommendations = recommended_set.intersection(ground_truth_set)\n",
    "    return len(relevant_recommendations) / k if k > 0 else 0\n",
    "\n",
    "def recall_at_k(recommended_games, ground_truth_games, k=3):\n",
    "    \"\"\"Calculate recall@k for recommendations\"\"\"\n",
    "    recommended_set = set(recommended_games[:k])\n",
    "    ground_truth_set = set(ground_truth_games)\n",
    "    relevant_recommendations = recommended_set.intersection(ground_truth_set)\n",
    "    return len(relevant_recommendations) / len(ground_truth_set) if len(ground_truth_set) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration: Let's simulate a ground truth set\n",
    "# In a real scenario, this would come from user studies or expert ratings\n",
    "# For our example, we'll use games with the same primary genre as a simple ground truth\n",
    "\n",
    "def evaluate_recommendations(game_info, recommendations, df, top_n=3):\n",
    "    \"\"\"Evaluate recommendations against a simple ground truth\"\"\"\n",
    "    if game_info is None or recommendations is None:\n",
    "        return None\n",
    "    \n",
    "    # Get the primary genre of the input game\n",
    "    primary_genre = game_info['primary_genre']\n",
    "    \n",
    "    # Find all games with the same primary genre (our simple ground truth)\n",
    "    ground_truth = df[df['primary_genre'] == primary_genre]['AppID'].tolist()\n",
    "    \n",
    "    # Remove the input game from ground truth\n",
    "    if game_info['AppID'] in ground_truth:\n",
    "        ground_truth.remove(game_info['AppID'])\n",
    "    \n",
    "    # Get the recommended game IDs\n",
    "    recommended_ids = recommendations['AppID'].tolist()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    prec = precision_at_k(recommended_ids, ground_truth, k=top_n)\n",
    "    rec = recall_at_k(recommended_ids, ground_truth, k=top_n)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nEvaluation Metrics:\")\n",
    "    print(f\"Precision@{top_n}: {prec:.4f}\")\n",
    "    print(f\"Recall@{top_n}: {rec:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return {'precision': prec, 'recall': rec, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
       "source": [
    "# Evaluate our recommendations\n",
    "test_game = get_game_from_image(test_image_url, df)\n",
    "\n",
    "print(\"\\n===== Evaluation of Genre-Based Recommendations =====\")\n",
    "genre_metrics = evaluate_recommendations(test_game, genre_recommendations, df)\n",
    "\n",
    "print(\"\\n===== Evaluation of SVM-Based Recommendations =====\")\n",
    "svm_metrics = evaluate_recommendations(test_game, svm_recommendations, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing SVM with KNN\n",
    "\n",
    "Now let's compare our SVM-based approach with the KNN approach implemented by our teammate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of SVM and KNN approaches\n",
    "print(\"===== Comparing SVM and KNN Approaches =====\")\n",
    "print(\"\\nSVM Approach:\")\n",
    "print(\"1. Classification-based: Uses SVM to learn relationships between features and genres\")\n",
    "print(\"2. Can leverage decision boundaries: Finds games that are classified similarly\")\n",
    "print(\"3. Handles high-dimensional data well: Works with many genre/category features\")\n",
    "print(\"4. Computationally more intensive for training, but faster for predictions\")\n",
    "\n",
    "print(\"\\nKNN Approach:\")\n",
    "print(\"1. Distance-based: Directly finds nearest neighbors in feature space\")\n",
    "print(\"2. Simple and intuitive: Easier to understand and implement\")\n",
    "print(\"3. No training phase: Can adapt to new data without retraining\")\n",
    "print(\"4. Computationally more intensive for predictions with large datasets\")\n",
    "\n",
    "# We would ideally compare actual performance metrics here if we had KNN results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. How to Try the Model\n",
    "\n",
    "Here's how you can use this SVM-based recommendation system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use the SVM model for recommendations\n",
    "\n",
    "def try_recommendation_system():\n",
    "    \"\"\"Function to try out the recommendation system with user input\"\"\"\n",
    "    # Instructions\n",
    "    print(\"===== Game Recommendation System (SVM) =====\")\n",
    "    print(\"This system recommends games based on a game image URL.\")\n",
    "    print(\"\\nInstructions:\")\n",
    "    print(\"1. Find a Steam game image URL\")\n",
    "    print(\"   - Usually in the format: https://cdn.akamai.steamstatic.com/steam/apps/[GAME_ID]/header.jpg\")\n",
    "    print(\"2. Enter the URL below\")\n",
    "    print(\"3. The system will identify the game and recommend similar games\")\n",
    "    \n",
    "    # Get user input\n",
    "    image_url = input(\"\\nEnter a Steam game image URL: \")\n",
    "    \n",
    "    # Make recommendations\n",
    "    return recommend_games(image_url, df, all_features_df, best_svm_model, method='genre')\n",
    "\n",
    "# Uncomment the line below to try the system interactively\n",
    "# recommendations = try_recommendation_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion and Future Improvements\n",
    "\n",
    "In this notebook, we have implemented an SVM-based game recommendation system that can identify a game from an image URL and suggest similar games based on features like genres, categories, and platforms.\n",
    "\n",
    "### Key findings:\n",
    "1. SVM can effectively classify games based on their features\n",
    "2. Genre and category similarity provides a strong basis for recommendations\n",
    "3. The SVM approach complements the KNN approach implemented by our teammate\n",
    "\n",
    "### Future improvements:\n",
    "1. Integrate image recognition to directly process game images/posters\n",
    "2. Incorporate user preferences and behavior for personalized recommendations\n",
    "3. Combine SVM and KNN approaches for potentially better recommendations\n",
    "4. Add more features such as user reviews, ratings, and playtime\n",
    "5. Implement a user interface for easier interaction with the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],