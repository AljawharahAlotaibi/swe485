{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Game Recommendation System!\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5005 entries, 0 to 5004\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   AppID                 5005 non-null   int64  \n",
      " 1   name                  5005 non-null   object \n",
      " 2   required_age          5005 non-null   int64  \n",
      " 3   price                 5005 non-null   float64\n",
      " 4   detailed_description  5005 non-null   object \n",
      " 5   header_image          5005 non-null   object \n",
      " 6   windows               5005 non-null   bool   \n",
      " 7   mac                   5005 non-null   bool   \n",
      " 8   linux                 5005 non-null   bool   \n",
      " 9   supported_languages   5005 non-null   object \n",
      " 10  categories_x          5005 non-null   int64  \n",
      " 11  genres_x              5005 non-null   int64  \n",
      " 12  publishers            5005 non-null   int64  \n",
      " 13  tags                  5005 non-null   int64  \n",
      " 14  genres_y              5005 non-null   object \n",
      " 15  categories_y          5005 non-null   object \n",
      "dtypes: bool(3), float64(1), int64(6), object(6)\n",
      "memory usage: 523.1+ KB\n",
      "Preparing our data...\n",
      "Created 92 features for each game!\n",
      "\n",
      "Training our models...\n",
      "Training with 3503 games, testing with 1502 games\n",
      "Training Decision Tree...\n",
      "Training Neural Network...\n",
      "Decision Tree Accuracy: 0.0000\n",
      "Neural Network Accuracy: 0.0000\n",
      "\n",
      "Model Accuracy Comparison:\n",
      "Decision Tree: 0.0000\n",
      "Neural Network: 0.0000\n",
      "The Decision Tree did better!\n",
      "\n",
      "Let's test our recommendation system!\n",
      "Testing with image: https://cdn.akamai.steamstatic.com/steam/apps/1514430/header.jpg?t=1684750957\n",
      "\n",
      "Starting the recommendation process...\n",
      "I found your game! It's Reek N' Havok\n",
      "\n",
      "Finding similar games to Reek N' Havok...\n",
      "\n",
      "You might also like these games:\n",
      "- Hexa Puzzle Saga (Similarity: 1.00)\n",
      "  Price: $-0.5986507368305405\n",
      "  Genres: ['Casual', 'Indie', 'Strategy']\n",
      "  Image: https://shared.akamai.steamstatic.com/store_item_assets/steam/apps/2397830/header.jpg?t=1698712710\n",
      "\n",
      "- Fliese (Similarity: 1.00)\n",
      "  Price: $-0.5310736741460439\n",
      "  Genres: ['Casual', 'Indie', 'Strategy']\n",
      "  Image: https://cdn.akamai.steamstatic.com/steam/apps/2264550/header.jpg?t=1675346035\n",
      "\n",
      "- Super Hero Flash Fist (Similarity: 1.00)\n",
      "  Price: $-0.3283424860925542\n",
      "  Genres: ['Casual', 'Indie', 'Strategy']\n",
      "  Image: https://cdn.akamai.steamstatic.com/steam/apps/1969960/header.jpg?t=1715534366\n",
      "\n",
      "All done! Our recommendation system is working!\n"
     ]
    }
   ],
   "source": [
    "# Game Recommendation System - Phase 2\n",
    "\n",
    "# Import the tools we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# skip for now.. \n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Step 1: Prepare our data\n",
    "def prepare_data(df):\n",
    "    print(\"Preparing our data...\")\n",
    "    \n",
    "    # Let's create features from the genres and categories\n",
    "    # We'll use a simple technique to convert text into numbers\n",
    "    \n",
    "    # Convert genres into features\n",
    "    genre_vectorizer = CountVectorizer(max_features=50)\n",
    "    genre_features = genre_vectorizer.fit_transform(df['genres_y'])\n",
    "    genre_feature_names = genre_vectorizer.get_feature_names_out()\n",
    "    genre_df = pd.DataFrame(genre_features.toarray(), columns=[f'genre_{g}' for g in genre_feature_names])\n",
    "    \n",
    "    # Convert categories into features\n",
    "    category_vectorizer = CountVectorizer(max_features=50)\n",
    "    category_features = category_vectorizer.fit_transform(df['categories_y'])\n",
    "    category_feature_names = category_vectorizer.get_feature_names_out()\n",
    "    category_df = pd.DataFrame(category_features.toarray(), columns=[f'cat_{c}' for c in category_feature_names])\n",
    "    \n",
    "    # Add price as a feature (games with similar prices might be similar)\n",
    "    # We'll create price ranges\n",
    "    # First handle NaN values in price\n",
    "    df['price'] = df['price'].fillna(0)\n",
    "    df['price_range'] = pd.cut(df['price'], bins=[0, 5, 10, 20, 100], labels=['free_to_cheap', 'budget', 'standard', 'premium'])\n",
    "    \n",
    "    # Handle any NaN values that might still be in price_range\n",
    "    # This can happen if there are prices outside our bin ranges\n",
    "    df['price_range'] = df['price_range'].cat.add_categories(['other'])\n",
    "    df['price_range'] = df['price_range'].fillna('other')\n",
    "    \n",
    "    price_encoder = OneHotEncoder(sparse_output=False)\n",
    "    price_features = price_encoder.fit_transform(df[['price_range']])\n",
    "    price_feature_names = [f\"price_{cat}\" for cat in price_encoder.categories_[0]]\n",
    "    price_df = pd.DataFrame(price_features, columns=price_feature_names)\n",
    "    \n",
    "    # Add platform features\n",
    "    platform_df = df[['windows', 'mac', 'linux']]\n",
    "    \n",
    "    # Combine all features\n",
    "    features_df = pd.concat([genre_df, category_df, price_df, platform_df], axis=1)\n",
    "    \n",
    "    print(f\"Created {features_df.shape[1]} features for each game!\")\n",
    "    \n",
    "    return features_df, genre_vectorizer, category_vectorizer, price_encoder\n",
    "\n",
    "# Step 2: Train our models\n",
    "def train_models(features_df, df):\n",
    "    print(\"\\nTraining our models...\")\n",
    "    \n",
    "    # Prepare our data\n",
    "    X = features_df  # All the features we created\n",
    "    y = df['AppID']  # The game ID (what we want to predict)\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    print(f\"Training with {X_train.shape[0]} games, testing with {X_test.shape[0]} games\")\n",
    "    \n",
    "    # Train our first model - Decision Tree\n",
    "    print(\"Training Decision Tree...\")\n",
    "    tree_model = DecisionTreeClassifier(max_depth=10)  # Limiting depth to avoid overfitting\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Train our second model - Neural Network\n",
    "    print(\"Training Neural Network...\")\n",
    "    # We'll use a simpler network since we have many features\n",
    "    nn_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, early_stopping=True)\n",
    "    nn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Test how good our models are\n",
    "    tree_pred = tree_model.predict(X_test)\n",
    "    tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "    \n",
    "    nn_pred = nn_model.predict(X_test)\n",
    "    nn_accuracy = accuracy_score(y_test, nn_pred)\n",
    "    \n",
    "    print(f\"Decision Tree Accuracy: {tree_accuracy:.4f}\")\n",
    "    print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")\n",
    "    \n",
    "    # Instead of visualization, just print a comparison\n",
    "    print(\"\\nModel Accuracy Comparison:\")\n",
    "    print(f\"Decision Tree: {tree_accuracy:.4f}\")\n",
    "    print(f\"Neural Network: {nn_accuracy:.4f}\")\n",
    "    \n",
    "    # Return the better model\n",
    "    if nn_accuracy > tree_accuracy:\n",
    "        print(\"The Neural Network did better!\")\n",
    "        return nn_model, \"Neural Network\"\n",
    "    else:\n",
    "        print(\"The Decision Tree did better!\")\n",
    "        return tree_model, \"Decision Tree\"\n",
    "\n",
    "# Step 3: Create a function to find similar games\n",
    "def find_similar_games(game_id, features_df, df, top_n=3):\n",
    "    print(f\"\\nFinding similar games to {df[df['AppID'] == game_id]['name'].values[0]}...\")\n",
    "    \n",
    "    # Get the features of our game\n",
    "    game_features = features_df.loc[df['AppID'] == game_id].values[0]\n",
    "    \n",
    "    # Calculate similarity with all other games\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # We'll use cosine similarity (like measuring the angle between two arrows)\n",
    "    # This is a common way to measure how similar two sets of features are\n",
    "    \n",
    "    for index, row in features_df.iterrows():\n",
    "        if df.iloc[index]['AppID'] == game_id:\n",
    "            continue  # Skip the game we already found\n",
    "        \n",
    "        # Get features for this game\n",
    "        other_features = row.values\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        # (dot product divided by product of magnitudes)\n",
    "        dot_product = np.dot(game_features, other_features)\n",
    "        game_magnitude = np.sqrt(np.dot(game_features, game_features))\n",
    "        other_magnitude = np.sqrt(np.dot(other_features, other_features))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if game_magnitude * other_magnitude == 0:\n",
    "            similarity = 0\n",
    "        else:\n",
    "            similarity = dot_product / (game_magnitude * other_magnitude)\n",
    "        \n",
    "        similarity_scores.append((df.iloc[index]['AppID'], similarity))\n",
    "    \n",
    "    # Sort by similarity and get top N\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_similar = similarity_scores[:top_n]\n",
    "    \n",
    "    return top_similar\n",
    "\n",
    "# Step 4: Make our recommendation function\n",
    "def recommend_games(model, model_name, features_df, df, image_url, vectorizers):\n",
    "    print(\"\\nStarting the recommendation process...\")\n",
    "    genre_vectorizer, category_vectorizer, price_encoder = vectorizers\n",
    "    \n",
    "    # In a real system, we would:\n",
    "    # 1. Download the image from the URL\n",
    "    # 2. Extract features from the image\n",
    "    # 3. Use the model to predict which game it is\n",
    "    \n",
    "    # For now, let's pretend we found the game by matching the image URL\n",
    "    found_game = df[df['header_image'] == image_url]\n",
    "    \n",
    "    if found_game.empty:\n",
    "        print(\"Sorry, I couldn't find a game with that image URL.\")\n",
    "        # For testing, let's just pick a random game\n",
    "        found_game = df.sample(1)\n",
    "        print(f\"Let's pretend we found: {found_game['name'].values[0]}\")\n",
    "    else:\n",
    "        print(f\"I found your game! It's {found_game['name'].values[0]}\")\n",
    "    \n",
    "    found_game_id = found_game['AppID'].values[0]\n",
    "    \n",
    "    # Find similar games\n",
    "    similar_games = find_similar_games(found_game_id, features_df, df)\n",
    "    \n",
    "    # Display recommendations\n",
    "    print(\"\\nYou might also like these games:\")\n",
    "    for game_id, score in similar_games:\n",
    "        game_info = df[df['AppID'] == game_id]\n",
    "        print(f\"- {game_info['name'].values[0]} (Similarity: {score:.2f})\")\n",
    "        print(f\"  Price: ${game_info['price'].values[0]}\")\n",
    "        print(f\"  Genres: {game_info['genres_y'].values[0]}\")\n",
    "        print(f\"  Image: {game_info['header_image'].values[0]}\")\n",
    "        print()\n",
    "    \n",
    "    return [id for id, _ in similar_games]\n",
    "\n",
    "# Put it all together\n",
    "def main():\n",
    "    print(\"Welcome to the Game Recommendation System!\")\n",
    "    \n",
    "    # Load the dataset from GitHub\n",
    "    url = \"https://raw.githubusercontent.com/AljawharahAlotaibi/swe485/main/Dataset/updated_cleaned_games.xls\"\n",
    "    df = pd.read_csv(url)\n",
    "    \n",
    "    # Drop any missing values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Show basic info about the dataset\n",
    "    print(\"Dataset information:\")\n",
    "    df.info()\n",
    "    \n",
    "    # Prepare our data\n",
    "    features_df, genre_vectorizer, category_vectorizer, price_encoder = prepare_data(df)\n",
    "    vectorizers = (genre_vectorizer, category_vectorizer, price_encoder)\n",
    "    \n",
    "    # Train our models\n",
    "    best_model, model_name = train_models(features_df, df)\n",
    "    \n",
    "    # Test our recommendation system\n",
    "    print(\"\\nLet's test our recommendation system!\")\n",
    "    \n",
    "    # Pick a random image URL from our dataset\n",
    "    random_game = df.sample(1)\n",
    "    image_url = random_game['header_image'].values[0]\n",
    "    print(f\"Testing with image: {image_url}\")\n",
    "    \n",
    "    # Get recommendations\n",
    "    recommended_games = recommend_games(best_model, model_name, features_df, df, image_url, vectorizers)\n",
    "    \n",
    "    print(\"All done!\")\n",
    "\n",
    "# program start\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train our models\n",
    "def train_models(features_df, df):\n",
    "    print(\"\\nTraining our models...\")\n",
    "    \n",
    "    # Prepare our data\n",
    "    X = features_df  # All the features we created\n",
    "    y = df['AppID']  # The game ID (what we want to predict)\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    print(f\"Training with # Game Recommendation System - Phase 2\n",
    "# This code helps recommend games based on a Steam game dataset\n",
    "\n",
    "# Import the tools we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# We'll skip visualization libraries\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Step 1: Prepare our data\n",
    "def prepare_data(df):\n",
    "    print(\"Preparing our data...\")\n",
    "    \n",
    "    # Let's create features from the genres and categories\n",
    "    # We'll use a simple technique to convert text into numbers\n",
    "    \n",
    "    # Convert genres into features\n",
    "    genre_vectorizer = CountVectorizer(max_features=50)\n",
    "    genre_features = genre_vectorizer.fit_transform(df['genres_y'])\n",
    "    genre_feature_names = genre_vectorizer.get_feature_names_out()\n",
    "    genre_df = pd.DataFrame(genre_features.toarray(), columns=[f'genre_{g}' for g in genre_feature_names])\n",
    "    \n",
    "    # Convert categories into features\n",
    "    category_vectorizer = CountVectorizer(max_features=50)\n",
    "    category_features = category_vectorizer.fit_transform(df['categories_y'])\n",
    "    category_feature_names = category_vectorizer.get_feature_names_out()\n",
    "    category_df = pd.DataFrame(category_features.toarray(), columns=[f'cat_{c}' for c in category_feature_names])\n",
    "    \n",
    "    # Add price as a feature (games with similar prices might be similar)\n",
    "    # We'll create price ranges\n",
    "    # First handle NaN values in price\n",
    "    df['price'] = df['price'].fillna(0)\n",
    "    df['price_range'] = pd.cut(df['price'], bins=[0, 5, 10, 20, 100], labels=['free_to_cheap', 'budget', 'standard', 'premium'])\n",
    "    \n",
    "    # Handle any NaN values that might still be in price_range\n",
    "    # This can happen if there are prices outside our bin ranges\n",
    "    df['price_range'] = df['price_range'].cat.add_categories(['other'])\n",
    "    df['price_range'] = df['price_range'].fillna('other')\n",
    "    \n",
    "    price_encoder = OneHotEncoder(sparse_output=False)\n",
    "    price_features = price_encoder.fit_transform(df[['price_range']])\n",
    "    price_feature_names = [f\"price_{cat}\" for cat in price_encoder.categories_[0]]\n",
    "    price_df = pd.DataFrame(price_features, columns=price_feature_names)\n",
    "    \n",
    "    # Add platform features\n",
    "    platform_df = df[['windows', 'mac', 'linux']]\n",
    "    \n",
    "    # Combine all features\n",
    "    features_df = pd.concat([genre_df, category_df, price_df, platform_df], axis=1)\n",
    "    \n",
    "    print(f\"Created {features_df.shape[1]} features for each game!\")\n",
    "    \n",
    "    return features_df, genre_vectorizer, category_vectorizer, price_encoder\n",
    "\n",
    "# Step 2: Train our models\n",
    "def train_models(features_df, df):\n",
    "    print(\"\\nTraining our models...\")\n",
    "    \n",
    "    # Prepare our data\n",
    "    X = features_df  # All the features we created\n",
    "    y = df['AppID']  # The game ID (what we want to predict)\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    print(f\"Training with {X_train.shape[0]} games, testing with {X_test.shape[0]} games\")\n",
    "    \n",
    "    # Scale the features for KNN and SVM (these algorithms work better with scaled data)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train our first model - Decision Tree\n",
    "    print(\"Training Decision Tree...\")\n",
    "    tree_model = DecisionTreeClassifier(max_depth=10)  # Limiting depth to avoid overfitting\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Train our second model - Neural Network\n",
    "    print(\"Training Neural Network...\")\n",
    "    # We'll use a simpler network since we have many features\n",
    "    nn_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, early_stopping=True)\n",
    "    nn_model.fit(X_train_scaled, y_train)  # Using scaled features for NN\n",
    "    \n",
    "    # Train our third model - K-Nearest Neighbors\n",
    "    print(\"Training K-Nearest Neighbors...\")\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)  # Using 5 neighbors\n",
    "    knn_model.fit(X_train_scaled, y_train)  # Using scaled features for KNN\n",
    "    \n",
    "    # Train our fourth model - Support Vector Machine\n",
    "    print(\"Training Support Vector Machine...\")\n",
    "    # Using a linear kernel for speed, can use 'rbf' for potentially better results\n",
    "    svm_model = SVC(kernel='linear', probability=True)\n",
    "    svm_model.fit(X_train_scaled, y_train)  # Using scaled features for SVM\n",
    "    \n",
    "    # Test how good our models are\n",
    "    tree_pred = tree_model.predict(X_test)\n",
    "    tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "    \n",
    "    nn_pred = nn_model.predict(X_test_scaled)  # Using scaled features\n",
    "    nn_accuracy = accuracy_score(y_test, nn_pred)\n",
    "    \n",
    "    knn_pred = knn_model.predict(X_test_scaled)  # Using scaled features\n",
    "    knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "    \n",
    "    svm_pred = svm_model.predict(X_test_scaled)  # Using scaled features\n",
    "    svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "    \n",
    "    print(f\"Decision Tree Accuracy: {tree_accuracy:.4f}\")\n",
    "    print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")\n",
    "    \n",
    "    # Detailed comparison of all models\n",
    "    print(\"\\n===== MODEL COMPARISON =====\")\n",
    "    print(f\"Decision Tree Accuracy: {tree_accuracy:.4f}\")\n",
    "    print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")\n",
    "    print(f\"K-Nearest Neighbors Accuracy: {knn_accuracy:.4f}\")\n",
    "    print(f\"Support Vector Machine Accuracy: {svm_accuracy:.4f}\")\n",
    "    \n",
    "    # Find the best model\n",
    "    accuracies = {\n",
    "        \"Decision Tree\": tree_accuracy,\n",
    "        \"Neural Network\": nn_accuracy,\n",
    "        \"K-Nearest Neighbors\": knn_accuracy,\n",
    "        \"Support Vector Machine\": svm_accuracy\n",
    "    }\n",
    "    \n",
    "    best_model_name = max(accuracies, key=accuracies.get)\n",
    "    best_accuracy = accuracies[best_model_name]\n",
    "    \n",
    "    print(\"\\nPerformance Comparison:\")\n",
    "    for model_name, accuracy in accuracies.items():\n",
    "        if model_name != best_model_name:\n",
    "            diff = best_accuracy - accuracy\n",
    "            print(f\"The {best_model_name} is better than {model_name} by {diff:.4f} points\")\n",
    "    \n",
    "    # Calculate precision, recall, and f1-score for all models\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    # For Decision Tree\n",
    "    tree_precision, tree_recall, tree_f1, _ = precision_recall_fscore_support(\n",
    "        y_test, tree_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # For Neural Network\n",
    "    nn_precision, nn_recall, nn_f1, _ = precision_recall_fscore_support(\n",
    "        y_test, nn_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # For KNN\n",
    "    knn_precision, knn_recall, knn_f1, _ = precision_recall_fscore_support(\n",
    "        y_test, knn_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # For SVM\n",
    "    svm_precision, svm_recall, svm_f1, _ = precision_recall_fscore_support(\n",
    "        y_test, svm_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(\"\\nDetailed Metrics:\")\n",
    "    print(f\"{'Metric':<15} {'Decision Tree':<15} {'Neural Network':<15} {'KNN':<15} {'SVM':<15}\")\n",
    "    print(\"-\" * 75)\n",
    "    print(f\"{'Accuracy':<15} {tree_accuracy:<15.4f} {nn_accuracy:<15.4f} {knn_accuracy:<15.4f} {svm_accuracy:<15.4f}\")\n",
    "    print(f\"{'Precision':<15} {tree_precision:<15.4f} {nn_precision:<15.4f} {knn_precision:<15.4f} {svm_precision:<15.4f}\")\n",
    "    print(f\"{'Recall':<15} {tree_recall:<15.4f} {nn_recall:<15.4f} {knn_recall:<15.4f} {svm_recall:<15.4f}\")\n",
    "    print(f\"{'F1 Score':<15} {tree_f1:<15.4f} {nn_f1:<15.4f} {knn_f1:<15.4f} {svm_f1:<15.4f}\")\n",
    "    \n",
    "    print(\"\\nWhat These Metrics Mean:\")\n",
    "    print(\"- Accuracy: How often the model is correct overall\")\n",
    "    print(\"- Precision: How accurate the model's positive predictions are\")\n",
    "    print(\"- Recall: How good the model is at finding all positive cases\")\n",
    "    print(\"- F1 Score: Balance between precision and recall\")\n",
    "    \n",
    "    print(\"\\nAlgorithm Strengths:\")\n",
    "    print(\"- Decision Tree: Easy to understand, handles mixed data types well\")\n",
    "    print(\"- Neural Network: Great at finding complex patterns, handles large feature sets\")\n",
    "    print(\"- K-Nearest Neighbors: Simple but effective, works well for similar items\")\n",
    "    print(\"- Support Vector Machine: Excellent for classification, handles high-dimensional data\")\n",
    "    \n",
    "    print(f\"\\nCONCLUSION: The {best_model_name} performs best overall for this task.\")\n",
    "    \n",
    "    # Select the best model\n",
    "    model_dict = {\n",
    "        \"Decision Tree\": (tree_model, tree_accuracy),\n",
    "        \"Neural Network\": (nn_model, nn_accuracy),\n",
    "        \"K-Nearest Neighbors\": (knn_model, knn_accuracy),\n",
    "        \"Support Vector Machine\": (svm_model, svm_accuracy)\n",
    "    }\n",
    "    \n",
    "    best_model_name = max(model_dict, key=lambda k: model_dict[k][1])\n",
    "    best_model = model_dict[best_model_name][0]\n",
    "    \n",
    "    print(f\"\\nThe {best_model_name} did best with an accuracy of {model_dict[best_model_name][1]:.4f}!\")\n",
    "    \n",
    "    # Also save the scaler for later use with the best model\n",
    "    return best_model, best_model_name, scaler\n",
    "\n",
    "# Step 3: Create a function to find similar games\n",
    "def find_similar_games(game_id, features_df, df, top_n=3):\n",
    "    print(f\"\\nFinding similar games to {df[df['AppID'] == game_id]['name'].values[0]}...\")\n",
    "    \n",
    "    # Get the features of our game\n",
    "    game_features = features_df.loc[df['AppID'] == game_id].values[0]\n",
    "    \n",
    "    # Calculate similarity with all other games\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # We'll use cosine similarity (like measuring the angle between two arrows)\n",
    "    # This is a common way to measure how similar two sets of features are\n",
    "    \n",
    "    for index, row in features_df.iterrows():\n",
    "        if df.iloc[index]['AppID'] == game_id:\n",
    "            continue  # Skip the game we already found\n",
    "        \n",
    "        # Get features for this game\n",
    "        other_features = row.values\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        # (dot product divided by product of magnitudes)\n",
    "        dot_product = np.dot(game_features, other_features)\n",
    "        game_magnitude = np.sqrt(np.dot(game_features, game_features))\n",
    "        other_magnitude = np.sqrt(np.dot(other_features, other_features))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if game_magnitude * other_magnitude == 0:\n",
    "            similarity = 0\n",
    "        else:\n",
    "            similarity = dot_product / (game_magnitude * other_magnitude)\n",
    "        \n",
    "        similarity_scores.append((df.iloc[index]['AppID'], similarity))\n",
    "    \n",
    "    # Sort by similarity and get top N\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_similar = similarity_scores[:top_n]\n",
    "    \n",
    "    return top_similar\n",
    "\n",
    "# Step 4: Make our recommendation function\n",
    "def recommend_games(model, model_name, features_df, df, image_url, vectorizers, scaler=None):\n",
    "    print(\"\\nStarting the recommendation process...\")\n",
    "    genre_vectorizer, category_vectorizer, price_encoder = vectorizers\n",
    "    \n",
    "    # In a real system, we would:\n",
    "    # 1. Download the image from the URL\n",
    "    # 2. Extract features from the image\n",
    "    # 3. Use the model to predict which game it is\n",
    "    \n",
    "    # For now, let's pretend we found the game by matching the image URL\n",
    "    found_game = df[df['header_image'] == image_url]\n",
    "    \n",
    "    if found_game.empty:\n",
    "        print(\"Sorry, I couldn't find a game with that image URL.\")\n",
    "        # For testing, let's just pick a random game\n",
    "        found_game = df.sample(1)\n",
    "        print(f\"Let's pretend we found: {found_game['name'].values[0]}\")\n",
    "    else:\n",
    "        print(f\"I found your game! It's {found_game['name'].values[0]}\")\n",
    "    \n",
    "    found_game_id = found_game['AppID'].values[0]\n",
    "    \n",
    "    # Find similar games\n",
    "    similar_games = find_similar_games(found_game_id, features_df, df)\n",
    "    \n",
    "    # Display recommendations\n",
    "    print(\"\\nYou might also like these games:\")\n",
    "    for game_id, score in similar_games:\n",
    "        game_info = df[df['AppID'] == game_id]\n",
    "        print(f\"- {game_info['name'].values[0]} (Similarity: {score:.2f})\")\n",
    "        print(f\"  Price: ${game_info['price'].values[0]}\")\n",
    "        print(f\"  Genres: {game_info['genres_y'].values[0]}\")\n",
    "        print(f\"  Image: {game_info['header_image'].values[0]}\")\n",
    "        print()\n",
    "    \n",
    "    return [id for id, _ in similar_games]\n",
    "\n",
    "# Put it all together\n",
    "def main():\n",
    "    print(\"Welcome to the Game Recommendation System!\")\n",
    "    \n",
    "    # Load the dataset from GitHub\n",
    "    url = \"https://raw.githubusercontent.com/AljawharahAlotaibi/swe485/main/Dataset/updated_cleaned_games.xls\"\n",
    "    df = pd.read_csv(url)\n",
    "    \n",
    "    # Drop any missing values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Show basic info about the dataset\n",
    "    print(\"Dataset information:\")\n",
    "    df.info()\n",
    "    \n",
    "    # Prepare our data\n",
    "    features_df, genre_vectorizer, category_vectorizer, price_encoder = prepare_data(df)\n",
    "    vectorizers = (genre_vectorizer, category_vectorizer, price_encoder)\n",
    "    \n",
    "    # Train our models\n",
    "    best_model, model_name, scaler = train_models(features_df, df)\n",
    "    \n",
    "    # Test our recommendation system\n",
    "    print(\"\\nLet's test our recommendation system!\")\n",
    "    \n",
    "    # Pick a random image URL from our dataset\n",
    "    random_game = df.sample(1)\n",
    "    image_url = random_game['header_image'].values[0]\n",
    "    print(f\"Testing with image: {image_url}\")\n",
    "    \n",
    "    # Get recommendations\n",
    "    recommended_games = recommend_games(best_model, model_name, features_df, df, image_url, vectorizers, scaler)\n",
    "    \n",
    "    print(\"All done! Our recommendation system is working!\")\n",
    "\n",
    "# This is where the program would start\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
